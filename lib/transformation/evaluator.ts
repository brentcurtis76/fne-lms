import Anthropic from '@anthropic-ai/sdk';

interface DimensionResponse {
  rubricItemId?: string;  // UUID (optional for legacy)
  sectionId?: string;     // Semantic key like "objetivo1_accion1_accion"
  response?: string;
  answer?: string;        // Alternative field name used by SequentialQuestions
  suggestedLevel?: number | null;
  confirmedLevel?: number | null;
  level?: string;         // Alternative field name (incipiente, en_desarrollo, etc)
  lastUpdated?: string;
  timestamp?: string;     // Alternative field name
}

interface RubricItem {
  id: string;
  objective_number: number;
  objective_text: string;
  action_number: number;
  action_text: string;
  dimension: 'cobertura' | 'frecuencia' | 'profundidad';
  level_1_descriptor: string;
  level_2_descriptor: string;
  level_3_descriptor: string;
  level_4_descriptor: string;
  initial_questions: string[];
  display_order: number;
}

interface DimensionEvaluation {
  rubricItemId: string;
  dimension: string;
  level: number;
  reasoning: string;
  evidence_quote: string;
  next_steps: string[];
}

interface AssessmentEvaluation {
  overall_stage: number; // 1-4
  overall_stage_label: 'Incipiente' | 'Emergente' | 'Avanzado' | 'Consolidado';
  dimension_evaluations: DimensionEvaluation[];
  strengths: string[];
  growth_areas: string[];
  summary: string;
  recommendations: string[];
}

/**
 * √Årea-specific focus and terminology for evaluation prompts
 */
const AREA_FOCUS = {
  personalizacion: `
## ENFOQUE: PERSONALIZACI√ìN

Esta v√≠a se centra en:
- **Individualizaci√≥n del aprendizaje**: Planes Personales de Crecimiento (PPC)
- **Autoconocimiento del estudiante**: Reflexi√≥n sobre fortalezas, intereses y metas
- **Tutor√≠as y acompa√±amiento**: Espacios de mentor√≠a 1:1 o peque√±os grupos
- **Flexibilidad de trayectorias**: Rutas diferenciadas seg√∫n ritmo y estilo

**Terminolog√≠a clave Personalizaci√≥n:**
- "Plan Personal de Crecimiento (PPC)": Documento donde estudiante define metas y estrategias
- "Tutor√≠as": Espacios de acompa√±amiento individual o grupal
- "Portafolio de aprendizaje": Colecci√≥n de evidencias del estudiante
- "Dise√±o Universal para el Aprendizaje (DUA)": Estrategias inclusivas en el aula
`,
  aprendizaje: `
## ENFOQUE: APRENDIZAJE

Esta v√≠a se centra en:
- **Metodolog√≠as activas**: Aprendizaje Basado en Proyectos (ABP), aprendizaje cooperativo
- **Estudiante en el centro**: Exploraci√≥n, indagaci√≥n, construcci√≥n de conocimiento
- **Interdisciplinariedad**: Proyectos que integran m√∫ltiples asignaturas
- **Ambientes de aprendizaje**: Espacios f√≠sicos y virtuales que facilitan la colaboraci√≥n

**Terminolog√≠a clave Aprendizaje:**
- "ABP (Aprendizaje Basado en Proyectos)": Metodolog√≠a donde estudiantes investigan y resuelven problemas reales
- "Proyectos interdisciplinarios": Integran objetivos de m√∫ltiples asignaturas
- "Cajas de aprendizaje": Recursos organizados por tema/proyecto para elecci√≥n de estudiantes
- "Br√∫julas": Documentos gu√≠a para proyectos y evaluaci√≥n
- "Equipos base": Grupos estables de estudiantes que colaboran durante el a√±o
- "Ambientes de aprendizaje": Espacios flexibles que fomentan colaboraci√≥n y autonom√≠a
`,
  evaluacion: `
## ENFOQUE: EVALUACI√ìN

Esta v√≠a se centra en:
- **Evaluaci√≥n formativa y formadora**: Estrategias continuas orientadas a acompa√±ar el aprendizaje
- **Retroalimentaci√≥n constructiva**: Feedback espec√≠fico, oportuno y que impulsa la mejora
- **Autoevaluaci√≥n y coevaluaci√≥n**: Participaci√≥n activa del estudiante en procesos evaluativos
- **Instrumentos diversificados**: R√∫bricas, portafolios, observaciones, informes descriptivos (no solo ex√°menes)
- **Metacognici√≥n sistem√°tica**: Reflexi√≥n sobre el propio proceso de aprendizaje

**Terminolog√≠a clave Evaluaci√≥n:**
- "Evaluaci√≥n formativa": Evaluaci√≥n continua que acompa√±a el proceso de aprendizaje, no solo certifica
- "Retroalimentaci√≥n": Feedback cualitativo espec√≠fico dirigido a mejorar, no solo calificaciones
- "Autoevaluaci√≥n": El estudiante eval√∫a su propio proceso, desempe√±o y estrategias
- "Coevaluaci√≥n": Estudiantes eval√∫an el trabajo de sus compa√±eros
- "R√∫brica": Instrumento que define criterios de desempe√±o en niveles claros
- "Portafolio": Colecci√≥n de evidencias del aprendizaje del estudiante a lo largo del tiempo
- "Metacognici√≥n": Reflexi√≥n sobre c√≥mo se aprende, qu√© estrategias funcionan y cu√°les no
- "Presentaciones de aprendizaje": Instancias donde estudiantes comparten evidencias ante familias
`,
};

/**
 * Build area-specific evaluation prompt
 */
function buildEvaluationPrompt(area: 'personalizacion' | 'aprendizaje' | 'evaluacion'): string {
  const areaLabels: Record<string, string> = {
    personalizacion: 'Personalizaci√≥n',
    aprendizaje: 'Aprendizaje',
    evaluacion: 'Evaluaci√≥n',
  };
  const areaLabel = areaLabels[area] || area;
  const areaFocus = AREA_FOCUS[area];

  return `Eres un experto en evaluaci√≥n educativa especializado en transformaci√≥n escolar en Chile.

Tu tarea es evaluar las respuestas de una comunidad educativa sobre su nivel de transformaci√≥n en la v√≠a de ${areaLabel}.
${areaFocus}

## CONTEXTO EDUCATIVO CHILENO

**Terminolog√≠a general:**
- "Generaci√≥n Tractor (GT)": Los primeros cursos donde la escuela decide enfocar la transformaci√≥n educativa de manera radical y r√°pida. T√≠picamente Pre-Kinder a 2¬∫ B√°sico, pero puede extenderse hasta 4¬∫ B√°sico. Cada a√±o se agrega un nuevo curso a GT. La velocidad var√≠a por escuela.
- "Generaci√≥n Innova (GI)": Todos los cursos que NO son GT. La transformaci√≥n es planificada e intencional, pero m√°s lenta y medida.
- "Curso": Equivalente a un grado o a√±o escolar (ej: 5¬∫ b√°sico)

**Criterios num√©ricos para COBERTURA:**
- Nivel 1: Menos de 50 estudiantes o 1-2 cursos aislados (piloto inicial)
- Nivel 2: 50-200 estudiantes, o implementaci√≥n en varios cursos de un nivel (ej: todo 5¬∫ y 6¬∫ b√°sico)
- Nivel 3: M√°s de 200 estudiantes o implementaci√≥n en la mayor√≠a de niveles educativos
- Nivel 4: Toda la matr√≠cula institucional de manera articulada y sistem√°tica

**Criterios para FRECUENCIA:**
- Nivel 1: Una vez al a√±o o espor√°dico
- Nivel 2: 2 veces al a√±o (semestral)
- Nivel 3: Trimestral, bimestral o mensual
- Nivel 4: Sistem√°tico e integrado en la vida escolar (semanal/continuo)

**Al evaluar:**
1. Busca evidencia num√©rica espec√≠fica (cantidad de estudiantes, cursos, frecuencia temporal)
2. Si el equipo menciona n√∫meros concretos, √∫salos para determinar el nivel seg√∫n los criterios arriba
3. No seas excesivamente conservador - si la evidencia claramente apunta a Nivel 2-3, as√≠gnalo
4. Valora la sistematizaci√≥n y el impacto, no solo la cantidad
5. Ejemplo: "160 estudiantes en 5¬∫ y 6¬∫ b√°sico" = Nivel 2 (implementaci√≥n significativa en varios cursos)

## Niveles de Desempe√±o

Para cada dimensi√≥n, determina el nivel bas√°ndote en estos criterios:

**Nivel 1 - Incipiente:**
- Conciencia inicial del tema
- Intentos espor√°dicos o aislados
- Sin sistematizaci√≥n
- Impacto m√≠nimo o no medible

**Nivel 2 - Emergente:**
- Pr√°cticas sistem√°ticas comenzando
- Implementaci√≥n en algunas √°reas o con algunos estudiantes
- Resultados iniciales visibles
- Requiere acompa√±amiento constante

**Nivel 3 - Avanzado:**
- Implementaci√≥n consistente y generalizada
- Resultados medibles y positivos
- Pr√°cticas institucionalizadas
- Autonom√≠a en la ejecuci√≥n

**Nivel 4 - Consolidado:**
- Excelencia sostenida en el tiempo
- Impacto transformador evidente
- Innovaci√≥n continua
- Modelo para otros

## Instrucciones

1. Lee cada respuesta cuidadosamente
2. Compara la evidencia con los descriptores de nivel de la r√∫brica
3. Identifica citas espec√≠ficas que justifiquen el nivel
4. Determina el nivel m√°s apropiado (1-4)
5. Proporciona pasos concretos de mejora

## Formato de Salida

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo esta estructura exacta:

{
  "dimension_evaluations": [
    {
      "rubricItemId": "uuid-del-item",
      "dimension": "nombre de la dimensi√≥n",
      "level": 2,
      "reasoning": "Justificaci√≥n clara del nivel asignado",
      "evidence_quote": "Cita textual de la respuesta que justifica el nivel",
      "next_steps": [
        "Paso concreto 1 para mejorar",
        "Paso concreto 2 para mejorar"
      ]
    }
  ],
  "overall_stage": 2,
  "overall_stage_label": "Emergente",
  "strengths": [
    "Fortaleza identificada 1",
    "Fortaleza identificada 2",
    "Fortaleza identificada 3"
  ],
  "growth_areas": [
    "√Årea de crecimiento 1",
    "√Årea de crecimiento 2",
    "√Årea de crecimiento 3"
  ],
  "summary": "Resumen ejecutivo del estado general de transformaci√≥n en 2-3 oraciones",
  "recommendations": [
    "Recomendaci√≥n prioritaria 1",
    "Recomendaci√≥n prioritaria 2",
    "Recomendaci√≥n prioritaria 3"
  ]
}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional antes o despu√©s.`;
}

// Keep old const for backward compatibility (defaults to Personalizaci√≥n)
const EVALUATION_PROMPT = buildEvaluationPrompt('personalizacion');

/**
 * Build area-specific objective evaluation prompt (simplified, no overall summary)
 */
function buildObjectiveEvaluationPrompt(area: 'personalizacion' | 'aprendizaje' | 'evaluacion'): string {
  const areaLabels: Record<string, string> = {
    personalizacion: 'Personalizaci√≥n',
    aprendizaje: 'Aprendizaje',
    evaluacion: 'Evaluaci√≥n',
  };
  const areaLabel = areaLabels[area] || area;
  const areaFocus = AREA_FOCUS[area];

  return `Eres un experto en evaluaci√≥n educativa especializado en transformaci√≥n escolar en Chile.

Tu tarea es evaluar las respuestas de una comunidad educativa para UN SOLO OBJETIVO de la v√≠a de ${areaLabel}.
${areaFocus}

## CONTEXTO EDUCATIVO CHILENO

**Terminolog√≠a importante:**
- "Generaci√≥n Tractor (GT)": Los primeros cursos donde la escuela decide enfocar la transformaci√≥n educativa de manera radical y r√°pida. T√≠picamente Pre-Kinder a 2¬∫ B√°sico, pero puede extenderse hasta 4¬∫ B√°sico. Cada a√±o se agrega un nuevo curso a GT. La velocidad var√≠a por escuela.
- "Generaci√≥n Innova (GI)": Todos los cursos que NO son GT. La transformaci√≥n es planificada e intencional, pero m√°s lenta y medida.
- "Curso": Equivalente a un grado o a√±o escolar (ej: 5¬∫ b√°sico)

**Criterios num√©ricos para COBERTURA:**
- Nivel 1: Menos de 50 estudiantes o 1-2 cursos aislados (piloto inicial)
- Nivel 2: 50-200 estudiantes, o implementaci√≥n en varios cursos de un nivel (ej: todo 5¬∫ y 6¬∫ b√°sico)
- Nivel 3: M√°s de 200 estudiantes o implementaci√≥n en la mayor√≠a de niveles educativos
- Nivel 4: Toda la matr√≠cula institucional de manera articulada y sistem√°tica

**Criterios para FRECUENCIA:**
- Nivel 1: Una vez al a√±o o espor√°dico
- Nivel 2: 2 veces al a√±o (semestral)
- Nivel 3: Trimestral, bimestral o mensual
- Nivel 4: Sistem√°tico e integrado en la vida escolar (semanal/continuo)

**Al evaluar:**
1. Busca evidencia num√©rica espec√≠fica (cantidad de estudiantes, cursos, frecuencia temporal)
2. Si el equipo menciona n√∫meros concretos, √∫salos para determinar el nivel seg√∫n los criterios arriba
3. No seas excesivamente conservador - si la evidencia claramente apunta a Nivel 2-3, as√≠gnalo
4. Valora la sistematizaci√≥n y el impacto, no solo la cantidad
5. Ejemplo: "160 estudiantes en 5¬∫ y 6¬∫ b√°sico" = Nivel 2 (implementaci√≥n significativa en varios cursos)

## Niveles de Desempe√±o

Para cada dimensi√≥n, determina el nivel bas√°ndote en estos criterios:

**Nivel 1 - Incipiente:**
- Conciencia inicial del tema
- Intentos espor√°dicos o aislados
- Sin sistematizaci√≥n
- Impacto m√≠nimo o no medible

**Nivel 2 - Emergente:**
- Pr√°cticas sistem√°ticas comenzando
- Implementaci√≥n en algunas √°reas o con algunos estudiantes
- Resultados iniciales visibles
- Requiere acompa√±amiento constante

**Nivel 3 - Avanzado:**
- Implementaci√≥n consistente y generalizada
- Resultados medibles y positivos
- Pr√°cticas institucionalizadas
- Autonom√≠a en la ejecuci√≥n

**Nivel 4 - Consolidado:**
- Excelencia sostenida en el tiempo
- Impacto transformador evidente
- Innovaci√≥n continua
- Modelo para otros

## Instrucciones

1. Lee cada respuesta cuidadosamente
2. Compara la evidencia con los descriptores de nivel de la r√∫brica
3. Identifica citas espec√≠ficas que justifiquen el nivel
4. Determina el nivel m√°s apropiado (1-4)
5. Proporciona pasos concretos de mejora

## Formato de Salida

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo esta estructura exacta:

{
  "dimension_evaluations": [
    {
      "rubricItemId": "uuid-del-item",
      "dimension": "nombre de la dimensi√≥n",
      "level": 2,
      "reasoning": "Justificaci√≥n clara del nivel asignado",
      "evidence_quote": "Cita textual de la respuesta que justifica el nivel",
      "next_steps": [
        "Paso concreto 1 para mejorar",
        "Paso concreto 2 para mejorar"
      ]
    }
  ]
}

IMPORTANTE:
- Responde SOLO con el JSON, sin texto adicional antes o despu√©s
- DEBES escapar correctamente las comillas dobles dentro de los valores de texto usando \"
- Ejemplo: "evidence_quote": "El docente dijo \\"esto es importante\\" en su respuesta"`;
}

// Keep old const for backward compatibility
const OBJECTIVE_EVALUATION_PROMPT = buildObjectiveEvaluationPrompt('personalizacion');

/**
 * Build area-specific summary prompt for objective-by-objective evaluation
 */
function buildSummaryPrompt(area: 'personalizacion' | 'aprendizaje' | 'evaluacion', dimensionEvaluations: any[]): string {
  const areaLabels: Record<string, string> = {
    personalizacion: 'Personalizaci√≥n',
    aprendizaje: 'Aprendizaje',
    evaluacion: 'Evaluaci√≥n',
  };
  const areaLabel = areaLabels[area] || area;

  return `Eres un experto en evaluaci√≥n educativa especializado en transformaci√≥n escolar en Chile.

Has evaluado las respuestas de una comunidad educativa sobre su nivel de transformaci√≥n en la v√≠a de ${areaLabel}.

A continuaci√≥n se presentan las evaluaciones detalladas de cada dimensi√≥n que ya has realizado.

Tu tarea ahora es generar un resumen ejecutivo que incluya:
1. Nivel general de transformaci√≥n (1-4)
2. Fortalezas principales (3-5 puntos)
3. √Åreas de crecimiento (3-5 puntos)
4. Resumen ejecutivo (2-3 oraciones)
5. Recomendaciones prioritarias (3-5 puntos)

## EVALUACIONES POR DIMENSI√ìN

${dimensionEvaluations.map((dimEval, idx) => `
**Dimensi√≥n ${idx + 1}: ${dimEval.dimension}**
- Nivel asignado: ${dimEval.level}
- Justificaci√≥n: ${dimEval.reasoning}
- Evidencia: "${dimEval.evidence_quote}"
`).join('\n')}

## CRITERIOS PARA NIVEL GENERAL

El nivel general debe reflejar el promedio ponderado de todas las dimensiones, considerando:
- **Nivel 1 - Incipiente**: Promedio 1.0-1.5 - Conciencia inicial, intentos aislados
- **Nivel 2 - Emergente**: Promedio 1.6-2.5 - Pr√°cticas comenzando, resultados iniciales
- **Nivel 3 - Avanzado**: Promedio 2.6-3.5 - Implementaci√≥n generalizada, pr√°cticas institucionalizadas
- **Nivel 4 - Consolidado**: Promedio 3.6-4.0 - Excelencia sostenida, innovaci√≥n continua

## FORMATO DE SALIDA

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo esta estructura exacta:

{
  "overall_stage": 2,
  "overall_stage_label": "Emergente",
  "strengths": [
    "Fortaleza identificada 1",
    "Fortaleza identificada 2",
    "Fortaleza identificada 3"
  ],
  "growth_areas": [
    "√Årea de crecimiento 1",
    "√Årea de crecimiento 2",
    "√Årea de crecimiento 3"
  ],
  "summary": "Resumen ejecutivo del estado general de transformaci√≥n en 2-3 oraciones completas y coherentes.",
  "recommendations": [
    "Recomendaci√≥n prioritaria 1",
    "Recomendaci√≥n prioritaria 2",
    "Recomendaci√≥n prioritaria 3"
  ]
}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional antes o despu√©s.`;
}

export class RubricEvaluator {
  private anthropic: Anthropic;
  private area: 'personalizacion' | 'aprendizaje' | 'evaluacion';
  private modelId: string;

  constructor(
    apiKey: string,
    area: 'personalizacion' | 'aprendizaje' | 'evaluacion' = 'personalizacion',
    modelId?: string
  ) {
    console.log('üîß RubricEvaluator constructor called');
    console.log('üìä API key length:', apiKey.length);
    console.log('üéØ √Årea:', area);

    this.area = area;
    // Use provided modelId, or fall back to env var, or default to Sonnet 4
    this.modelId = modelId || process.env.ANTHROPIC_MODEL_ID || 'claude-sonnet-4-6';
    console.log('ü§ñ Model ID:', this.modelId);

    try {
      this.anthropic = new Anthropic({
        apiKey,
      });
      console.log('‚úÖ Anthropic client initialized successfully');
    } catch (err: any) {
      console.error('‚ùå Error initializing Anthropic client:', err);
      throw err;
    }

    console.log('‚úÖ RubricEvaluator constructor complete');
  }

  /**
   * Sanitize Claude's JSON response to fix common formatting issues
   * Specifically handles unescaped quotes in string values that cause parse errors
   */
  private sanitizeClaudeJSON(jsonText: string): string {
    try {
      // Strategy: Use a lenient JSON repair approach
      // 1. Try to parse as-is first
      try {
        JSON.parse(jsonText);
        return jsonText; // Already valid JSON
      } catch (e) {
        // Continue to repair attempts
      }

      // 2. Common issue: Unescaped quotes within string values
      // Replace problematic patterns in string contexts
      // This is a heuristic approach - we look for patterns like:
      // "evidence_quote": "text with "unescaped" quotes"

      let sanitized = jsonText;

      // Find all string values and escape internal quotes
      // Match pattern: "key": "value with potential "internal quotes" here"
      // We need to be careful not to break valid JSON structure

      // More robust approach: Parse character by character, tracking context
      let result = '';
      let inString = false;
      let inKey = false;
      let afterColon = false;
      let braceDepth = 0;
      let escapeNext = false;

      for (let i = 0; i < sanitized.length; i++) {
        const char = sanitized[i];
        const prevChar = i > 0 ? sanitized[i - 1] : '';
        const nextChar = i < sanitized.length - 1 ? sanitized[i + 1] : '';

        // Handle escape sequences
        if (escapeNext) {
          result += char;
          escapeNext = false;
          continue;
        }

        if (char === '\\') {
          result += char;
          escapeNext = true;
          continue;
        }

        // Track JSON structure depth
        if (!inString) {
          if (char === '{' || char === '[') braceDepth++;
          if (char === '}' || char === ']') braceDepth--;
        }

        // Handle quote characters
        if (char === '"') {
          if (!inString) {
            // Starting a new string
            inString = true;
            inKey = !afterColon; // If we haven't seen a colon yet, this is a key
            result += char;
          } else {
            // Potentially ending a string
            // Check if this is actually the end or a quote inside the value
            // Heuristic: Look ahead for comma, close brace/bracket, or colon
            const lookAhead = sanitized.substring(i + 1, i + 10).trim();
            const isRealEnd = lookAhead.startsWith(',') ||
                             lookAhead.startsWith('}') ||
                             lookAhead.startsWith(']') ||
                             lookAhead.startsWith(':');

            if (isRealEnd || inKey) {
              // This is the actual end of the string
              inString = false;
              if (inKey) afterColon = false;
              result += char;
            } else {
              // This is an internal quote that should be escaped
              result += '\\"';
            }
          }
        } else {
          result += char;
          if (char === ':' && !inString) {
            afterColon = true;
          }
          if (char === ',' && !inString) {
            afterColon = false;
            inKey = false;
          }
        }
      }

      console.log('üîß JSON sanitization applied');
      return result;

    } catch (sanitizeError) {
      console.warn('‚ö†Ô∏è JSON sanitization failed, returning original:', sanitizeError);
      return jsonText; // Return original if sanitization fails
    }
  }

  /**
   * Extract contextual _accion responses (open-ended qualitative answers)
   * These don't map to rubric items but provide valuable context for evaluation
   *
   * Note: Only works with semantic keys (objetivo1_accion1_accion format).
   * UUID-format keys don't have _accion responses - they use rubric IDs directly.
   */
  private extractAccionResponses(
    responses: Record<string, DimensionResponse>
  ): Record<string, { objectiveNum: number; actionNum: number; text: string }> {
    const accionResponses: Record<string, { objectiveNum: number; actionNum: number; text: string }> = {};

    // Early return if responses are in UUID format (no _accion keys possible)
    const firstKey = Object.keys(responses)[0];
    if (!firstKey) {
      console.log('üìù No responses to extract _accion from');
      return accionResponses;
    }

    // UUID keys have 4+ hyphens, semantic keys have 0-2
    const hyphenCount = (firstKey.match(/-/g) || []).length;
    if (hyphenCount >= 4) {
      console.log('üìù Responses are in UUID format - no _accion keys to extract');
      return accionResponses;
    }

    for (const [key, response] of Object.entries(responses)) {
      if (key.endsWith('_accion')) {
        const match = key.match(/objetivo(\d+)_accion(\d+)_accion/);
        if (match) {
          const text = response.response || response.answer || '';
          if (text.trim()) {
            accionResponses[key] = {
              objectiveNum: parseInt(match[1]),
              actionNum: parseInt(match[2]),
              text: text.trim()
            };
          }
        } else {
          // Key ends with _accion but doesn't match expected pattern - log for debugging
          console.warn(`‚ö†Ô∏è Unexpected _accion key format: ${key}`);
        }
      }
    }

    console.log(`üìù Extracted ${Object.keys(accionResponses).length} contextual _accion responses`);
    return accionResponses;
  }

  /**
   * Map semantic keys to rubric item UUIDs
   */
  private mapResponsesToRubricItems(
    rubricItems: RubricItem[],
    responses: Record<string, DimensionResponse>
  ): Record<string, DimensionResponse> {
    console.log('üó∫Ô∏è mapResponsesToRubricItems called');
    console.log('üìä Rubric items count:', rubricItems.length);
    console.log('üìä Responses count:', Object.keys(responses).length);

    const mappedResponses: Record<string, DimensionResponse> = {};

    // Check if responses are already in UUID format
    const firstKey = Object.keys(responses)[0];
    if (!firstKey) {
      console.log('‚ö†Ô∏è No responses to map');
      return responses;
    }

    console.log('üîç Evaluator: First key format:', firstKey);

    // UUIDs have 4-5 hyphens, semantic keys have 0-2
    // UUID example: a6bed0f2-cf31-4bfd-b1a3-299965de7359 (4 hyphens)
    // Semantic examples: obj1-accion (1 hyphen), objetivo1_accion1_accion (0 hyphens)
    const hyphenCount = (firstKey.match(/-/g) || []).length;
    const isUUID = hyphenCount >= 4;

    console.log('üîç Evaluator: Hyphen count:', hyphenCount);
    console.log('üîç Evaluator: Detected as UUID?', isUUID);

    if (isUUID) {
      console.log('‚úÖ Keys are already in UUID format');
      return responses; // Already in correct format
    }

    // Otherwise, map semantic keys to UUID keys
    console.log('üîÑ Converting semantic keys to UUID keys...');

    let successCount = 0;
    let accionCount = 0;

    for (const [semanticKey, response] of Object.entries(responses)) {
      // Parse semantic key: "objetivo1_accion1_accion" or "objetivo1_accion1_cobertura"
      const match = semanticKey.match(/objetivo(\d+)_accion(\d+)_(\w+)/);

      if (!match) {
        console.warn(`‚ö†Ô∏è Key doesn't match pattern: ${semanticKey}`);
        continue;
      }

      const [, objectiveNum, actionNum, dimensionType] = match;

      // Skip _accion responses - they're contextual, not rubric-mapped
      // They'll be extracted separately via extractAccionResponses()
      if (dimensionType === 'accion') {
        accionCount++;
        continue; // Don't try to map to rubric - these are qualitative context
      }

      // Find matching rubric item for dimension responses
      const rubricItem = rubricItems.find(item =>
        item.objective_number === parseInt(objectiveNum) &&
        item.action_number === parseInt(actionNum) &&
        item.dimension === dimensionType
      );

      if (rubricItem) {
        // Normalize the response format
        mappedResponses[rubricItem.id] = {
          rubricItemId: rubricItem.id,
          response: response.response || response.answer || '',
          suggestedLevel: response.suggestedLevel ??
                         (response.level ? this.parseLevelToNumber(response.level) : null),
          confirmedLevel: response.confirmedLevel ??
                         (response.level ? this.parseLevelToNumber(response.level) : null),
          lastUpdated: response.lastUpdated || response.timestamp || new Date().toISOString()
        };

        successCount++;
      } else {
        console.warn(`‚ö†Ô∏è No rubric item found for dimension: obj${objectiveNum}, act${actionNum}, ${dimensionType}`);
      }
    }

    console.log(`‚úÖ Mapping complete: ${successCount} dimension responses mapped, ${accionCount} contextual _accion responses (handled separately)`);

    return mappedResponses;
  }

  /**
   * Parse level string to number
   */
  private parseLevelToNumber(level: string | number): number {
    if (typeof level === 'number') return level;

    const levelMap: Record<string, number> = {
      'incipiente': 1,
      'en_desarrollo': 2,
      'emergente': 2,  // Alternative name
      'avanzado': 3,
      'consolidado': 4
    };

    return levelMap[level.toLowerCase()] || 1;
  }

  /**
   * Evaluate all responses against the rubric using Claude Sonnet 4.5
   */
  async evaluateAssessment(
    responses: Record<string, DimensionResponse>,
    rubricItems: RubricItem[]
  ): Promise<AssessmentEvaluation> {
    console.log('ü§ñ evaluateAssessment called');
    console.log('üìä Input responses:', Object.keys(responses).length);
    console.log('üìä Input rubric items:', rubricItems.length);

    // Extract contextual _accion responses (qualitative data not in rubric)
    console.log('‚úÖ Extracting contextual _accion responses...');
    const accionResponses = this.extractAccionResponses(responses);

    // Map semantic keys to rubric UUIDs if needed
    console.log('‚úÖ Mapping responses to rubric items...');
    const mappedResponses = this.mapResponsesToRubricItems(rubricItems, responses);
    console.log('‚úÖ Mapped responses count:', Object.keys(mappedResponses).length);

    // Build evaluation context (including _accion context)
    console.log('‚úÖ Building evaluation context...');
    const evaluationContext = this.buildEvaluationContext(mappedResponses, rubricItems, accionResponses);
    console.log('‚úÖ Context built. Length:', evaluationContext.length, 'characters');

    // Check if context is too large
    if (evaluationContext.length > 150000) {
      console.warn('‚ö†Ô∏è WARNING: Context might be too large!', evaluationContext.length, 'characters');
    }

    // Combine prompt and context (use √°rea-specific prompt)
    const areaPrompt = buildEvaluationPrompt(this.area);
    const fullPrompt = `${areaPrompt}\n\n${evaluationContext}`;
    console.log('üìè Full prompt length:', fullPrompt.length, 'characters');

    // üîç DIAGNOSTIC: Log the first 5000 characters of the prompt to see what Claude receives
    console.log('üîç DIAGNOSTIC: First 5000 chars of prompt sent to Claude:');
    console.log(fullPrompt.substring(0, 5000));
    console.log('...[truncated]');

    // Call Claude API
    console.log('‚úÖ Calling Anthropic API...');
    console.log('üìã Using model:', this.modelId);
    console.log('üìã Max tokens: 16000');
    console.log('üìã Temperature: 0.3');

    let message;
    try {
      message = await this.anthropic.messages.create({
        model: this.modelId,
        max_tokens: 16000, // Increased to handle full 33-dimension evaluation JSON
        temperature: 0.3, // Lower temperature for more consistent evaluations
        messages: [
          {
            role: 'user',
            content: fullPrompt,
          },
        ],
      });
      console.log('‚úÖ API call successful');
      console.log('üìä Response usage:', {
        inputTokens: message.usage?.input_tokens || 0,
        outputTokens: message.usage?.output_tokens || 0
      });
    } catch (apiError: any) {
      console.error('‚ùå ANTHROPIC API ERROR - FULL DETAILS:');
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('Error type:', apiError.constructor?.name || 'Unknown');
      console.error('Error message:', apiError.message);
      console.error('Error stack:', apiError.stack);

      if (apiError.status) {
        console.error('HTTP status:', apiError.status);
      }

      if (apiError.error) {
        console.error('API error object:', JSON.stringify(apiError.error, null, 2));
      }

      if (apiError.type) {
        console.error('Error type field:', apiError.type);
      }

      if (apiError.response) {
        console.error('Response data:', apiError.response);
      }

      if (apiError.headers) {
        console.error('Response headers:', apiError.headers);
      }

      console.error('Full error object keys:', Object.keys(apiError));
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');

      // Throw error with all details
      throw new Error(
        `Error en llamada a Anthropic API: ${apiError.message || 'Unknown error'}. ` +
        `Status: ${apiError.status || 'N/A'}. ` +
        `Type: ${apiError.type || 'N/A'}. ` +
        `Details: ${JSON.stringify(apiError.error || {})}`
      );
    }

    // Extract JSON from response
    console.log('‚úÖ Extracting JSON from response...');
    const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
    console.log('üìä Response text length:', responseText.length);

    // Strip markdown code blocks if present
    let jsonText = responseText.trim();

    // Check if wrapped in ```json ... ```
    if (jsonText.startsWith('```json')) {
      console.log('üîß Removing markdown code block markers (```json)...');
      // Remove ```json from start (including newline)
      jsonText = jsonText.substring(7).trim();

      // Remove ``` from end
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }

      jsonText = jsonText.trim();
      console.log('‚úÖ Markdown removed. New length:', jsonText.length);
    } else if (jsonText.startsWith('```')) {
      console.log('üîß Removing generic code block markers (```)...');
      // Handle ``` without "json"
      jsonText = jsonText.substring(3).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
      console.log('‚úÖ Markdown removed. New length:', jsonText.length);
    }

    try {
      console.log('‚úÖ Parsing JSON...');
      console.log('üìä First 100 chars of cleaned JSON:', jsonText.substring(0, 100));
      const evaluation = JSON.parse(jsonText) as AssessmentEvaluation;
      console.log('‚úÖ JSON parsed successfully');

      // Validate evaluation structure
      console.log('‚úÖ Validating evaluation structure...');
      if (!this.isValidEvaluation(evaluation)) {
        console.error('‚ùå Invalid evaluation structure');
        console.error('Evaluation object keys:', Object.keys(evaluation));
        console.error('Evaluation object:', JSON.stringify(evaluation, null, 2).substring(0, 1000));
        throw new Error('Invalid evaluation structure returned by AI');
      }

      console.log('‚úÖ Evaluation valid');
      console.log('üìä Evaluation summary:', {
        overallStage: evaluation.overall_stage,
        dimensionCount: evaluation.dimension_evaluations?.length || 0,
        strengthsCount: evaluation.strengths?.length || 0,
        growthAreasCount: evaluation.growth_areas?.length || 0
      });

      return evaluation;
    } catch (error: any) {
      console.error('‚ùå JSON PARSING ERROR - FULL DETAILS:');
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('Error type:', error.constructor?.name || 'Unknown');
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('Original response length:', responseText.length);
      console.error('Cleaned JSON length:', jsonText.length);
      console.error('Cleaned JSON (first 1000 chars):', jsonText.substring(0, 1000));
      console.error('Cleaned JSON (last 500 chars):', jsonText.substring(Math.max(0, jsonText.length - 500)));
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');

      // Try to determine if it's a JSON parse error or validation error
      if (error instanceof SyntaxError) {
        throw new Error(
          `Error al parsear respuesta JSON del AI: ${error.message}. ` +
          `La respuesta no es JSON v√°lido. Primeros 200 caracteres: ${jsonText.substring(0, 200)}`
        );
      } else {
        throw new Error(
          `Error al procesar evaluaci√≥n del AI: ${error.message}. ` +
          `La estructura de la respuesta no es v√°lida.`
        );
      }
    }
  }

  /**
   * Evaluate a single objective's responses
   * This is used for progressive evaluation to avoid timeouts
   */
  async evaluateObjective(
    objectiveNumber: number,
    responses: Record<string, DimensionResponse>,
    rubricItems: RubricItem[]
  ): Promise<{ dimension_evaluations: DimensionEvaluation[] }> {
    console.log(`üéØ evaluateObjective called for Objective ${objectiveNumber}`);
    console.log('üìä Input responses:', Object.keys(responses).length);
    console.log('üìä Input rubric items:', rubricItems.length);

    // Filter rubric items to only this objective
    const objectiveItems = rubricItems.filter(
      item => item.objective_number === objectiveNumber
    );
    console.log(`üìä Filtered to ${objectiveItems.length} items for Objective ${objectiveNumber}`);

    if (objectiveItems.length === 0) {
      throw new Error(`No rubric items found for Objective ${objectiveNumber}`);
    }

    // Map semantic keys to rubric UUIDs if needed
    console.log('‚úÖ Mapping responses to rubric items...');
    const mappedResponses = this.mapResponsesToRubricItems(objectiveItems, responses);
    console.log('‚úÖ Mapped responses count:', Object.keys(mappedResponses).length);

    // Build evaluation context for this objective only
    console.log('‚úÖ Building evaluation context for objective...');
    const evaluationContext = this.buildEvaluationContext(mappedResponses, objectiveItems);
    console.log('‚úÖ Context built. Length:', evaluationContext.length, 'characters');

    // Combine prompt and context (using simpler objective-level prompt with √°rea)
    const areaPrompt = buildObjectiveEvaluationPrompt(this.area);
    const fullPrompt = `${areaPrompt}\n\n${evaluationContext}`;
    console.log('üìè Full prompt length:', fullPrompt.length, 'characters');

    // Call Claude API
    console.log('‚úÖ Calling Anthropic API for objective evaluation...');
    console.log('üìã Using model:', this.modelId);
    console.log('üìã Max tokens: 8000'); // Increased to handle detailed evidence_quote fields
    console.log('üìã Temperature: 0.3');

    let message;
    try {
      message = await this.anthropic.messages.create({
        model: this.modelId,
        max_tokens: 8000, // Increased from 4000 to prevent truncation
        temperature: 0.3,
        messages: [
          {
            role: 'user',
            content: fullPrompt,
          },
        ],
      });
      console.log('‚úÖ API call successful');
      console.log('üìä Response usage:', {
        inputTokens: message.usage?.input_tokens || 0,
        outputTokens: message.usage?.output_tokens || 0
      });
      console.log('üìä Stop reason:', message.stop_reason);

      // CRITICAL: Check if response was truncated due to token limit
      if (message.stop_reason === 'max_tokens') {
        console.error('‚ùå RESPONSE TRUNCATED: Hit max_tokens limit');
        console.error('üìä Token usage:', message.usage);
        throw new Error(
          `La respuesta del AI fue truncada por l√≠mite de tokens. ` +
          `Objetivo ${objectiveNumber} requiere m√°s tokens para completar la evaluaci√≥n. ` +
          `Por favor, contacte al administrador del sistema.`
        );
      }
    } catch (apiError: any) {
      console.error('‚ùå ANTHROPIC API ERROR in evaluateObjective:');
      console.error('Error message:', apiError.message);
      throw new Error(
        `Error en llamada a Anthropic API para Objetivo ${objectiveNumber}: ${apiError.message || 'Unknown error'}`
      );
    }

    // Extract JSON from response
    console.log('‚úÖ Extracting JSON from response...');
    const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
    console.log('üìä Response text length:', responseText.length);

    // Strip markdown code blocks if present
    let jsonText = responseText.trim();
    if (jsonText.startsWith('```json')) {
      jsonText = jsonText.substring(7).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    } else if (jsonText.startsWith('```')) {
      jsonText = jsonText.substring(3).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    }

    // Validate JSON completeness before sanitization
    // Check for basic JSON structure completeness
    const jsonTrimmed = jsonText.trim();
    const startsWithBrace = jsonTrimmed.startsWith('{');
    const endsWithBrace = jsonTrimmed.endsWith('}');

    if (!startsWithBrace || !endsWithBrace) {
      console.error('‚ùå JSON appears truncated or malformed');
      console.error('Starts with {:', startsWithBrace);
      console.error('Ends with }:', endsWithBrace);
      console.error('Last 100 chars:', jsonTrimmed.slice(-100));
      throw new Error(
        `Respuesta JSON incompleta del AI (truncada o malformada). ` +
        `Esto puede indicar que el l√≠mite de tokens fue alcanzado durante la generaci√≥n.`
      );
    }

    // Sanitize JSON to fix common issues from Claude responses
    // Specifically: unescaped quotes in string values
    console.log('‚úÖ Sanitizing JSON response...');
    jsonText = this.sanitizeClaudeJSON(jsonText);

    try {
      console.log('‚úÖ Parsing JSON...');
      const evaluation = JSON.parse(jsonText) as { dimension_evaluations: DimensionEvaluation[] };
      console.log('‚úÖ JSON parsed successfully');

      // Validate structure
      if (!evaluation.dimension_evaluations || !Array.isArray(evaluation.dimension_evaluations)) {
        throw new Error('Invalid objective evaluation structure: missing dimension_evaluations array');
      }

      console.log('‚úÖ Objective evaluation valid');
      console.log('üìä Dimension evaluations count:', evaluation.dimension_evaluations.length);

      return evaluation;
    } catch (error: any) {
      console.error('‚ùå JSON PARSING ERROR in evaluateObjective:');
      console.error('Error message:', error.message);
      console.error('Cleaned JSON (first 1000 chars):', jsonText.substring(0, 1000));
      throw new Error(
        `Error al parsear respuesta JSON del AI para Objetivo ${objectiveNumber}: ${error.message}`
      );
    }
  }

  /**
   * Generate overall summary from all objective evaluations
   * This is called after all objectives have been evaluated individually
   */
  async generateOverallSummary(
    objectiveEvaluations: Record<number, { dimension_evaluations: DimensionEvaluation[] }>
  ): Promise<{
    overall_stage: number;
    overall_stage_label: 'Incipiente' | 'Emergente' | 'Avanzado' | 'Consolidado';
    strengths: string[];
    growth_areas: string[];
    summary: string;
    recommendations: string[];
  }> {
    console.log('üìä generateOverallSummary called');
    console.log('üìä Objective evaluations count:', Object.keys(objectiveEvaluations).length);

    // Collect all dimension evaluations
    const allDimensionEvaluations: DimensionEvaluation[] = [];
    for (const objNum of Object.keys(objectiveEvaluations).sort()) {
      const objEval = objectiveEvaluations[parseInt(objNum)];
      if (objEval?.dimension_evaluations) {
        allDimensionEvaluations.push(...objEval.dimension_evaluations);
      }
    }

    console.log('üìä Total dimension evaluations:', allDimensionEvaluations.length);

    // Build summary prompt (use √°rea-specific builder)
    const summaryPrompt = buildSummaryPrompt(this.area, allDimensionEvaluations);

    // Call Claude API
    console.log('‚úÖ Calling Anthropic API for overall summary...');
    console.log('üìã Using model:', this.modelId);
    console.log('üìã Max tokens: 2000');
    console.log('üìã Temperature: 0.3');

    let message;
    try {
      message = await this.anthropic.messages.create({
        model: this.modelId,
        max_tokens: 2000,
        temperature: 0.3,
        messages: [
          {
            role: 'user',
            content: summaryPrompt,
          },
        ],
      });
      console.log('‚úÖ API call successful');
      console.log('üìä Response usage:', {
        inputTokens: message.usage?.input_tokens || 0,
        outputTokens: message.usage?.output_tokens || 0
      });
    } catch (apiError: any) {
      console.error('‚ùå ANTHROPIC API ERROR in generateOverallSummary:');
      console.error('Error message:', apiError.message);
      throw new Error(
        `Error en llamada a Anthropic API para resumen general: ${apiError.message || 'Unknown error'}`
      );
    }

    // Extract JSON from response
    console.log('‚úÖ Extracting JSON from response...');
    const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
    console.log('üìä Response text length:', responseText.length);

    // Strip markdown code blocks if present
    let jsonText = responseText.trim();
    if (jsonText.startsWith('```json')) {
      jsonText = jsonText.substring(7).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    } else if (jsonText.startsWith('```')) {
      jsonText = jsonText.substring(3).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    }

    try {
      console.log('‚úÖ Parsing JSON...');
      const summary = JSON.parse(jsonText);
      console.log('‚úÖ JSON parsed successfully');

      // Validate structure
      if (!summary.overall_stage || !summary.overall_stage_label ||
          !Array.isArray(summary.strengths) || !Array.isArray(summary.growth_areas) ||
          !summary.summary || !Array.isArray(summary.recommendations)) {
        throw new Error('Invalid summary structure');
      }

      console.log('‚úÖ Overall summary valid');
      console.log('üìä Overall stage:', summary.overall_stage, '-', summary.overall_stage_label);

      return summary;
    } catch (error: any) {
      console.error('‚ùå JSON PARSING ERROR in generateOverallSummary:');
      console.error('Error message:', error.message);
      console.error('Cleaned JSON (first 1000 chars):', jsonText.substring(0, 1000));
      throw new Error(
        `Error al parsear respuesta JSON del resumen general: ${error.message}`
      );
    }
  }

  /**
   * Build the evaluation context with responses and rubric
   */
  private buildEvaluationContext(
    responses: Record<string, DimensionResponse>,
    rubricItems: RubricItem[],
    accionResponses?: Record<string, { objectiveNum: number; actionNum: number; text: string }>
  ): string {
    let context = '## RESPUESTAS DE LA COMUNIDAD EDUCATIVA\n\n';

    // Group by objective and action
    const grouped = this.groupRubricItems(rubricItems);

    for (const objective of grouped) {
      context += `### Objetivo ${objective.objectiveNumber}: ${objective.objectiveText}\n\n`;

      for (const action of objective.actions) {
        context += `#### Acci√≥n ${action.actionNumber}: ${action.actionText}\n\n`;

        // Add contextual description from _accion response if available
        // This provides qualitative context about how the school implements this action
        if (accionResponses) {
          const accionKey = `objetivo${objective.objectiveNumber}_accion${action.actionNumber}_accion`;
          const accionData = accionResponses[accionKey];
          if (accionData && accionData.text) {
            context += `**Contexto del equipo sobre esta acci√≥n:**\n"${accionData.text}"\n\n`;
          }
        }

        // Add each dimension response
        for (const [dimensionType, rubricItem] of Object.entries(action.dimensions)) {
          const item = rubricItem as RubricItem;  // Type assertion
          const response = responses[item.id];

          context += `**Dimensi√≥n: ${this.getDimensionLabel(dimensionType as any)}**\n`;
          context += `Rubric Item ID: ${item.id}\n\n`;

          context += `Descriptores de nivel:\n`;
          context += `- Nivel 1: ${item.level_1_descriptor}\n`;
          context += `- Nivel 2: ${item.level_2_descriptor}\n`;
          context += `- Nivel 3: ${item.level_3_descriptor}\n`;
          context += `- Nivel 4: ${item.level_4_descriptor}\n\n`;

          if (response && response.response && response.response.trim()) {
            context += `Respuesta del equipo:\n"${response.response}"\n\n`;
          } else {
            context += `Respuesta del equipo: (Sin respuesta)\n\n`;
          }

          context += '---\n\n';
        }
      }
    }

    return context;
  }

  /**
   * Group rubric items by objective and action
   */
  private groupRubricItems(rubricItems: RubricItem[]) {
    const objectivesMap: Record<number, any> = {};

    rubricItems.forEach((item) => {
      if (!objectivesMap[item.objective_number]) {
        objectivesMap[item.objective_number] = {
          objectiveNumber: item.objective_number,
          objectiveText: item.objective_text,
          actions: [],
        };
      }

      const objective = objectivesMap[item.objective_number];
      let action = objective.actions.find((a: any) => a.actionNumber === item.action_number);

      if (!action) {
        action = {
          actionNumber: item.action_number,
          actionText: item.action_text,
          dimensions: {},
        };
        objective.actions.push(action);
      }

      action.dimensions[item.dimension] = item;
    });

    const objectives = Object.values(objectivesMap).sort((a: any, b: any) => a.objectiveNumber - b.objectiveNumber);
    objectives.forEach((obj: any) => {
      obj.actions.sort((a: any, b: any) => a.actionNumber - b.actionNumber);
    });

    return objectives;
  }

  /**
   * Get Spanish label for dimension type
   */
  private getDimensionLabel(dimension: 'cobertura' | 'frecuencia' | 'profundidad'): string {
    const labels = {
      cobertura: 'Cobertura',
      frecuencia: 'Frecuencia',
      profundidad: 'Profundidad',
    };
    return labels[dimension];
  }

  /**
   * Validate evaluation structure
   */
  private isValidEvaluation(evaluation: any): evaluation is AssessmentEvaluation {
    return (
      evaluation &&
      typeof evaluation === 'object' &&
      Array.isArray(evaluation.dimension_evaluations) &&
      typeof evaluation.overall_stage === 'number' &&
      typeof evaluation.overall_stage_label === 'string' &&
      Array.isArray(evaluation.strengths) &&
      Array.isArray(evaluation.growth_areas) &&
      typeof evaluation.summary === 'string' &&
      Array.isArray(evaluation.recommendations)
    );
  }
}
