import Anthropic from '@anthropic-ai/sdk';

interface DimensionResponse {
  rubricItemId?: string;  // UUID (optional for legacy)
  sectionId?: string;     // Semantic key like "objetivo1_accion1_accion"
  response?: string;
  answer?: string;        // Alternative field name used by SequentialQuestions
  suggestedLevel?: number | null;
  confirmedLevel?: number | null;
  level?: string;         // Alternative field name (incipiente, en_desarrollo, etc)
  lastUpdated?: string;
  timestamp?: string;     // Alternative field name
}

interface RubricItem {
  id: string;
  objective_number: number;
  objective_text: string;
  action_number: number;
  action_text: string;
  dimension: 'cobertura' | 'frecuencia' | 'profundidad';
  level_1_descriptor: string;
  level_2_descriptor: string;
  level_3_descriptor: string;
  level_4_descriptor: string;
  initial_questions: string[];
  display_order: number;
}

interface DimensionEvaluation {
  rubricItemId: string;
  dimension: string;
  level: number;
  reasoning: string;
  evidence_quote: string;
  next_steps: string[];
}

interface AssessmentEvaluation {
  overall_stage: number; // 1-4
  overall_stage_label: 'Incipiente' | 'Emergente' | 'Avanzado' | 'Consolidado';
  dimension_evaluations: DimensionEvaluation[];
  strengths: string[];
  growth_areas: string[];
  summary: string;
  recommendations: string[];
}

const EVALUATION_PROMPT = `Eres un experto en evaluaci√≥n educativa especializado en transformaci√≥n escolar en Chile.

Tu tarea es evaluar las respuestas de una comunidad educativa sobre su nivel de transformaci√≥n en la v√≠a de Personalizaci√≥n.

## CONTEXTO EDUCATIVO CHILENO

**Terminolog√≠a importante:**
- "Generaci√≥n Tractor (GT)": Los primeros cursos donde la escuela decide enfocar la transformaci√≥n educativa de manera radical y r√°pida. T√≠picamente Pre-Kinder a 2¬∫ B√°sico, pero puede extenderse hasta 4¬∫ B√°sico. Cada a√±o se agrega un nuevo curso a GT. La velocidad var√≠a por escuela.
- "Generaci√≥n Innova (GI)": Todos los cursos que NO son GT. La transformaci√≥n es planificada e intencional, pero m√°s lenta y medida.
- "Curso": Equivalente a un grado o a√±o escolar (ej: 5¬∫ b√°sico)

**Criterios num√©ricos para COBERTURA:**
- Nivel 1: Menos de 50 estudiantes o 1-2 cursos aislados (piloto inicial)
- Nivel 2: 50-200 estudiantes, o implementaci√≥n en varios cursos de un nivel (ej: todo 5¬∫ y 6¬∫ b√°sico)
- Nivel 3: M√°s de 200 estudiantes o implementaci√≥n en la mayor√≠a de niveles educativos
- Nivel 4: Toda la matr√≠cula institucional de manera articulada y sistem√°tica

**Criterios para FRECUENCIA:**
- Nivel 1: Una vez al a√±o o espor√°dico
- Nivel 2: 2 veces al a√±o (semestral)
- Nivel 3: Trimestral, bimestral o mensual
- Nivel 4: Sistem√°tico e integrado en la vida escolar (semanal/continuo)

**Al evaluar:**
1. Busca evidencia num√©rica espec√≠fica (cantidad de estudiantes, cursos, frecuencia temporal)
2. Si el equipo menciona n√∫meros concretos, √∫salos para determinar el nivel seg√∫n los criterios arriba
3. No seas excesivamente conservador - si la evidencia claramente apunta a Nivel 2-3, as√≠gnalo
4. Valora la sistematizaci√≥n y el impacto, no solo la cantidad
5. Ejemplo: "160 estudiantes en 5¬∫ y 6¬∫ b√°sico" = Nivel 2 (implementaci√≥n significativa en varios cursos)

## Niveles de Desempe√±o

Para cada dimensi√≥n, determina el nivel bas√°ndote en estos criterios:

**Nivel 1 - Incipiente:**
- Conciencia inicial del tema
- Intentos espor√°dicos o aislados
- Sin sistematizaci√≥n
- Impacto m√≠nimo o no medible

**Nivel 2 - Emergente:**
- Pr√°cticas sistem√°ticas comenzando
- Implementaci√≥n en algunas √°reas o con algunos estudiantes
- Resultados iniciales visibles
- Requiere acompa√±amiento constante

**Nivel 3 - Avanzado:**
- Implementaci√≥n consistente y generalizada
- Resultados medibles y positivos
- Pr√°cticas institucionalizadas
- Autonom√≠a en la ejecuci√≥n

**Nivel 4 - Consolidado:**
- Excelencia sostenida en el tiempo
- Impacto transformador evidente
- Innovaci√≥n continua
- Modelo para otros

## Instrucciones

1. Lee cada respuesta cuidadosamente
2. Compara la evidencia con los descriptores de nivel de la r√∫brica
3. Identifica citas espec√≠ficas que justifiquen el nivel
4. Determina el nivel m√°s apropiado (1-4)
5. Proporciona pasos concretos de mejora

## Formato de Salida

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo esta estructura exacta:

{
  "dimension_evaluations": [
    {
      "rubricItemId": "uuid-del-item",
      "dimension": "nombre de la dimensi√≥n",
      "level": 2,
      "reasoning": "Justificaci√≥n clara del nivel asignado",
      "evidence_quote": "Cita textual de la respuesta que justifica el nivel",
      "next_steps": [
        "Paso concreto 1 para mejorar",
        "Paso concreto 2 para mejorar"
      ]
    }
  ],
  "overall_stage": 2,
  "overall_stage_label": "Emergente",
  "strengths": [
    "Fortaleza identificada 1",
    "Fortaleza identificada 2",
    "Fortaleza identificada 3"
  ],
  "growth_areas": [
    "√Årea de crecimiento 1",
    "√Årea de crecimiento 2",
    "√Årea de crecimiento 3"
  ],
  "summary": "Resumen ejecutivo del estado general de transformaci√≥n en 2-3 oraciones",
  "recommendations": [
    "Recomendaci√≥n prioritaria 1",
    "Recomendaci√≥n prioritaria 2",
    "Recomendaci√≥n prioritaria 3"
  ]
}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional antes o despu√©s.`;

// Simplified prompt for objective-level evaluation (no overall summary needed)
const OBJECTIVE_EVALUATION_PROMPT = `Eres un experto en evaluaci√≥n educativa especializado en transformaci√≥n escolar en Chile.

Tu tarea es evaluar las respuestas de una comunidad educativa para UN SOLO OBJETIVO de la v√≠a de Personalizaci√≥n.

## CONTEXTO EDUCATIVO CHILENO

**Terminolog√≠a importante:**
- "Generaci√≥n Tractor (GT)": Los primeros cursos donde la escuela decide enfocar la transformaci√≥n educativa de manera radical y r√°pida. T√≠picamente Pre-Kinder a 2¬∫ B√°sico, pero puede extenderse hasta 4¬∫ B√°sico. Cada a√±o se agrega un nuevo curso a GT. La velocidad var√≠a por escuela.
- "Generaci√≥n Innova (GI)": Todos los cursos que NO son GT. La transformaci√≥n es planificada e intencional, pero m√°s lenta y medida.
- "Curso": Equivalente a un grado o a√±o escolar (ej: 5¬∫ b√°sico)

**Criterios num√©ricos para COBERTURA:**
- Nivel 1: Menos de 50 estudiantes o 1-2 cursos aislados (piloto inicial)
- Nivel 2: 50-200 estudiantes, o implementaci√≥n en varios cursos de un nivel (ej: todo 5¬∫ y 6¬∫ b√°sico)
- Nivel 3: M√°s de 200 estudiantes o implementaci√≥n en la mayor√≠a de niveles educativos
- Nivel 4: Toda la matr√≠cula institucional de manera articulada y sistem√°tica

**Criterios para FRECUENCIA:**
- Nivel 1: Una vez al a√±o o espor√°dico
- Nivel 2: 2 veces al a√±o (semestral)
- Nivel 3: Trimestral, bimestral o mensual
- Nivel 4: Sistem√°tico e integrado en la vida escolar (semanal/continuo)

**Al evaluar:**
1. Busca evidencia num√©rica espec√≠fica (cantidad de estudiantes, cursos, frecuencia temporal)
2. Si el equipo menciona n√∫meros concretos, √∫salos para determinar el nivel seg√∫n los criterios arriba
3. No seas excesivamente conservador - si la evidencia claramente apunta a Nivel 2-3, as√≠gnalo
4. Valora la sistematizaci√≥n y el impacto, no solo la cantidad
5. Ejemplo: "160 estudiantes en 5¬∫ y 6¬∫ b√°sico" = Nivel 2 (implementaci√≥n significativa en varios cursos)

## Niveles de Desempe√±o

Para cada dimensi√≥n, determina el nivel bas√°ndote en estos criterios:

**Nivel 1 - Incipiente:**
- Conciencia inicial del tema
- Intentos espor√°dicos o aislados
- Sin sistematizaci√≥n
- Impacto m√≠nimo o no medible

**Nivel 2 - Emergente:**
- Pr√°cticas sistem√°ticas comenzando
- Implementaci√≥n en algunas √°reas o con algunos estudiantes
- Resultados iniciales visibles
- Requiere acompa√±amiento constante

**Nivel 3 - Avanzado:**
- Implementaci√≥n consistente y generalizada
- Resultados medibles y positivos
- Pr√°cticas institucionalizadas
- Autonom√≠a en la ejecuci√≥n

**Nivel 4 - Consolidado:**
- Excelencia sostenida en el tiempo
- Impacto transformador evidente
- Innovaci√≥n continua
- Modelo para otros

## Instrucciones

1. Lee cada respuesta cuidadosamente
2. Compara la evidencia con los descriptores de nivel de la r√∫brica
3. Identifica citas espec√≠ficas que justifiquen el nivel
4. Determina el nivel m√°s apropiado (1-4)
5. Proporciona pasos concretos de mejora

## Formato de Salida

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo esta estructura exacta:

{
  "dimension_evaluations": [
    {
      "rubricItemId": "uuid-del-item",
      "dimension": "nombre de la dimensi√≥n",
      "level": 2,
      "reasoning": "Justificaci√≥n clara del nivel asignado",
      "evidence_quote": "Cita textual de la respuesta que justifica el nivel",
      "next_steps": [
        "Paso concreto 1 para mejorar",
        "Paso concreto 2 para mejorar"
      ]
    }
  ]
}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional antes o despu√©s.`;

export class RubricEvaluator {
  private anthropic: Anthropic;

  constructor(apiKey: string) {
    console.log('üîß RubricEvaluator constructor called');
    console.log('üìä API key length:', apiKey.length);

    try {
      this.anthropic = new Anthropic({
        apiKey,
      });
      console.log('‚úÖ Anthropic client initialized successfully');
    } catch (err: any) {
      console.error('‚ùå Error initializing Anthropic client:', err);
      throw err;
    }

    console.log('‚úÖ RubricEvaluator constructor complete');
  }

  /**
   * Map semantic keys to rubric item UUIDs
   */
  private mapResponsesToRubricItems(
    rubricItems: RubricItem[],
    responses: Record<string, DimensionResponse>
  ): Record<string, DimensionResponse> {
    console.log('üó∫Ô∏è mapResponsesToRubricItems called');
    console.log('üìä Rubric items count:', rubricItems.length);
    console.log('üìä Responses count:', Object.keys(responses).length);

    const mappedResponses: Record<string, DimensionResponse> = {};

    // Check if responses are already in UUID format
    const firstKey = Object.keys(responses)[0];
    if (!firstKey) {
      console.log('‚ö†Ô∏è No responses to map');
      return responses;
    }

    console.log('üîç Evaluator: First key format:', firstKey);

    // UUIDs have 4-5 hyphens, semantic keys have 0-2
    // UUID example: a6bed0f2-cf31-4bfd-b1a3-299965de7359 (4 hyphens)
    // Semantic examples: obj1-accion (1 hyphen), objetivo1_accion1_accion (0 hyphens)
    const hyphenCount = (firstKey.match(/-/g) || []).length;
    const isUUID = hyphenCount >= 4;

    console.log('üîç Evaluator: Hyphen count:', hyphenCount);
    console.log('üîç Evaluator: Detected as UUID?', isUUID);

    if (isUUID) {
      console.log('‚úÖ Keys are already in UUID format');
      return responses; // Already in correct format
    }

    // Otherwise, map semantic keys to UUID keys
    console.log('üîÑ Converting semantic keys to UUID keys...');

    let successCount = 0;
    let failCount = 0;

    for (const [semanticKey, response] of Object.entries(responses)) {
      // Parse semantic key: "objetivo1_accion1_accion" or "objetivo1_accion1_cobertura"
      const match = semanticKey.match(/objetivo(\d+)_accion(\d+)_(\w+)/);

      if (!match) {
        console.warn(`‚ö†Ô∏è Key doesn't match pattern: ${semanticKey}`);
        failCount++;
        continue;
      }

      const [, objectiveNum, actionNum, dimensionType] = match;

      // Map dimension type to rubric dimension
      const dimensionMap: Record<string, string> = {
        'accion': 'accion',
        'cobertura': 'cobertura',
        'frecuencia': 'frecuencia',
        'profundidad': 'profundidad'
      };

      const dimension = dimensionMap[dimensionType];

      // Find matching rubric item
      const rubricItem = rubricItems.find(item =>
        item.objective_number === parseInt(objectiveNum) &&
        item.action_number === parseInt(actionNum) &&
        item.dimension === dimension
      );

      if (rubricItem) {
        // Normalize the response format
        mappedResponses[rubricItem.id] = {
          rubricItemId: rubricItem.id,
          response: response.response || response.answer || '',
          suggestedLevel: response.suggestedLevel ??
                         (response.level ? this.parseLevelToNumber(response.level) : null),
          confirmedLevel: response.confirmedLevel ??
                         (response.level ? this.parseLevelToNumber(response.level) : null),
          lastUpdated: response.lastUpdated || response.timestamp || new Date().toISOString()
        };

        successCount++;
        console.log(`‚úÖ Mapped: ${semanticKey} ‚Üí ${rubricItem.id}`);
      } else {
        failCount++;
        console.warn(`‚ö†Ô∏è No rubric item found for: obj${objectiveNum}, act${actionNum}, ${dimension}`);
      }
    }

    console.log(`‚úÖ Mapping complete: ${successCount} success, ${failCount} failed`);

    return mappedResponses;
  }

  /**
   * Parse level string to number
   */
  private parseLevelToNumber(level: string | number): number {
    if (typeof level === 'number') return level;

    const levelMap: Record<string, number> = {
      'incipiente': 1,
      'en_desarrollo': 2,
      'emergente': 2,  // Alternative name
      'avanzado': 3,
      'consolidado': 4
    };

    return levelMap[level.toLowerCase()] || 1;
  }

  /**
   * Evaluate all responses against the rubric using Claude Sonnet 4.5
   */
  async evaluateAssessment(
    responses: Record<string, DimensionResponse>,
    rubricItems: RubricItem[]
  ): Promise<AssessmentEvaluation> {
    console.log('ü§ñ evaluateAssessment called');
    console.log('üìä Input responses:', Object.keys(responses).length);
    console.log('üìä Input rubric items:', rubricItems.length);

    // Map semantic keys to rubric UUIDs if needed
    console.log('‚úÖ Mapping responses to rubric items...');
    const mappedResponses = this.mapResponsesToRubricItems(rubricItems, responses);
    console.log('‚úÖ Mapped responses count:', Object.keys(mappedResponses).length);

    // Build evaluation context
    console.log('‚úÖ Building evaluation context...');
    const evaluationContext = this.buildEvaluationContext(mappedResponses, rubricItems);
    console.log('‚úÖ Context built. Length:', evaluationContext.length, 'characters');

    // Check if context is too large
    if (evaluationContext.length > 150000) {
      console.warn('‚ö†Ô∏è WARNING: Context might be too large!', evaluationContext.length, 'characters');
    }

    // Combine prompt and context
    const fullPrompt = `${EVALUATION_PROMPT}\n\n${evaluationContext}`;
    console.log('üìè Full prompt length:', fullPrompt.length, 'characters');

    // üîç DIAGNOSTIC: Log the first 5000 characters of the prompt to see what Claude receives
    console.log('üîç DIAGNOSTIC: First 5000 chars of prompt sent to Claude:');
    console.log(fullPrompt.substring(0, 5000));
    console.log('...[truncated]');

    // Call Claude API
    console.log('‚úÖ Calling Anthropic API...');
    const MODEL = 'claude-sonnet-4-20250514';  // Upgraded from Haiku for better reasoning
    console.log('üìã Using model:', MODEL);
    console.log('üìã Max tokens: 6000');
    console.log('üìã Temperature: 0.3');

    let message;
    try {
      message = await this.anthropic.messages.create({
        model: MODEL,
        max_tokens: 6000,
        temperature: 0.3, // Lower temperature for more consistent evaluations
        messages: [
          {
            role: 'user',
            content: fullPrompt,
          },
        ],
      });
      console.log('‚úÖ API call successful');
      console.log('üìä Response usage:', {
        inputTokens: message.usage?.input_tokens || 0,
        outputTokens: message.usage?.output_tokens || 0
      });
    } catch (apiError: any) {
      console.error('‚ùå ANTHROPIC API ERROR - FULL DETAILS:');
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('Error type:', apiError.constructor?.name || 'Unknown');
      console.error('Error message:', apiError.message);
      console.error('Error stack:', apiError.stack);

      if (apiError.status) {
        console.error('HTTP status:', apiError.status);
      }

      if (apiError.error) {
        console.error('API error object:', JSON.stringify(apiError.error, null, 2));
      }

      if (apiError.type) {
        console.error('Error type field:', apiError.type);
      }

      if (apiError.response) {
        console.error('Response data:', apiError.response);
      }

      if (apiError.headers) {
        console.error('Response headers:', apiError.headers);
      }

      console.error('Full error object keys:', Object.keys(apiError));
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');

      // Throw error with all details
      throw new Error(
        `Error en llamada a Anthropic API: ${apiError.message || 'Unknown error'}. ` +
        `Status: ${apiError.status || 'N/A'}. ` +
        `Type: ${apiError.type || 'N/A'}. ` +
        `Details: ${JSON.stringify(apiError.error || {})}`
      );
    }

    // Extract JSON from response
    console.log('‚úÖ Extracting JSON from response...');
    const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
    console.log('üìä Response text length:', responseText.length);

    // Strip markdown code blocks if present
    let jsonText = responseText.trim();

    // Check if wrapped in ```json ... ```
    if (jsonText.startsWith('```json')) {
      console.log('üîß Removing markdown code block markers (```json)...');
      // Remove ```json from start (including newline)
      jsonText = jsonText.substring(7).trim();

      // Remove ``` from end
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }

      jsonText = jsonText.trim();
      console.log('‚úÖ Markdown removed. New length:', jsonText.length);
    } else if (jsonText.startsWith('```')) {
      console.log('üîß Removing generic code block markers (```)...');
      // Handle ``` without "json"
      jsonText = jsonText.substring(3).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
      console.log('‚úÖ Markdown removed. New length:', jsonText.length);
    }

    try {
      console.log('‚úÖ Parsing JSON...');
      console.log('üìä First 100 chars of cleaned JSON:', jsonText.substring(0, 100));
      const evaluation = JSON.parse(jsonText) as AssessmentEvaluation;
      console.log('‚úÖ JSON parsed successfully');

      // Validate evaluation structure
      console.log('‚úÖ Validating evaluation structure...');
      if (!this.isValidEvaluation(evaluation)) {
        console.error('‚ùå Invalid evaluation structure');
        console.error('Evaluation object keys:', Object.keys(evaluation));
        console.error('Evaluation object:', JSON.stringify(evaluation, null, 2).substring(0, 1000));
        throw new Error('Invalid evaluation structure returned by AI');
      }

      console.log('‚úÖ Evaluation valid');
      console.log('üìä Evaluation summary:', {
        overallStage: evaluation.overall_stage,
        dimensionCount: evaluation.dimension_evaluations?.length || 0,
        strengthsCount: evaluation.strengths?.length || 0,
        growthAreasCount: evaluation.growth_areas?.length || 0
      });

      return evaluation;
    } catch (error: any) {
      console.error('‚ùå JSON PARSING ERROR - FULL DETAILS:');
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('Error type:', error.constructor?.name || 'Unknown');
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('Original response length:', responseText.length);
      console.error('Cleaned JSON length:', jsonText.length);
      console.error('Cleaned JSON (first 1000 chars):', jsonText.substring(0, 1000));
      console.error('Cleaned JSON (last 500 chars):', jsonText.substring(Math.max(0, jsonText.length - 500)));
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');

      // Try to determine if it's a JSON parse error or validation error
      if (error instanceof SyntaxError) {
        throw new Error(
          `Error al parsear respuesta JSON del AI: ${error.message}. ` +
          `La respuesta no es JSON v√°lido. Primeros 200 caracteres: ${jsonText.substring(0, 200)}`
        );
      } else {
        throw new Error(
          `Error al procesar evaluaci√≥n del AI: ${error.message}. ` +
          `La estructura de la respuesta no es v√°lida.`
        );
      }
    }
  }

  /**
   * Evaluate a single objective's responses
   * This is used for progressive evaluation to avoid timeouts
   */
  async evaluateObjective(
    objectiveNumber: number,
    responses: Record<string, DimensionResponse>,
    rubricItems: RubricItem[]
  ): Promise<{ dimension_evaluations: DimensionEvaluation[] }> {
    console.log(`üéØ evaluateObjective called for Objective ${objectiveNumber}`);
    console.log('üìä Input responses:', Object.keys(responses).length);
    console.log('üìä Input rubric items:', rubricItems.length);

    // Filter rubric items to only this objective
    const objectiveItems = rubricItems.filter(
      item => item.objective_number === objectiveNumber
    );
    console.log(`üìä Filtered to ${objectiveItems.length} items for Objective ${objectiveNumber}`);

    if (objectiveItems.length === 0) {
      throw new Error(`No rubric items found for Objective ${objectiveNumber}`);
    }

    // Map semantic keys to rubric UUIDs if needed
    console.log('‚úÖ Mapping responses to rubric items...');
    const mappedResponses = this.mapResponsesToRubricItems(objectiveItems, responses);
    console.log('‚úÖ Mapped responses count:', Object.keys(mappedResponses).length);

    // Build evaluation context for this objective only
    console.log('‚úÖ Building evaluation context for objective...');
    const evaluationContext = this.buildEvaluationContext(mappedResponses, objectiveItems);
    console.log('‚úÖ Context built. Length:', evaluationContext.length, 'characters');

    // Combine prompt and context (using simpler objective-level prompt)
    const fullPrompt = `${OBJECTIVE_EVALUATION_PROMPT}\n\n${evaluationContext}`;
    console.log('üìè Full prompt length:', fullPrompt.length, 'characters');

    // Call Claude API
    console.log('‚úÖ Calling Anthropic API for objective evaluation...');
    const MODEL = 'claude-sonnet-4-20250514';
    console.log('üìã Using model:', MODEL);
    console.log('üìã Max tokens: 4000'); // Smaller since we don't need overall summary
    console.log('üìã Temperature: 0.3');

    let message;
    try {
      message = await this.anthropic.messages.create({
        model: MODEL,
        max_tokens: 4000, // Smaller for objective-level evaluation
        temperature: 0.3,
        messages: [
          {
            role: 'user',
            content: fullPrompt,
          },
        ],
      });
      console.log('‚úÖ API call successful');
      console.log('üìä Response usage:', {
        inputTokens: message.usage?.input_tokens || 0,
        outputTokens: message.usage?.output_tokens || 0
      });
    } catch (apiError: any) {
      console.error('‚ùå ANTHROPIC API ERROR in evaluateObjective:');
      console.error('Error message:', apiError.message);
      throw new Error(
        `Error en llamada a Anthropic API para Objetivo ${objectiveNumber}: ${apiError.message || 'Unknown error'}`
      );
    }

    // Extract JSON from response
    console.log('‚úÖ Extracting JSON from response...');
    const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
    console.log('üìä Response text length:', responseText.length);

    // Strip markdown code blocks if present
    let jsonText = responseText.trim();
    if (jsonText.startsWith('```json')) {
      jsonText = jsonText.substring(7).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    } else if (jsonText.startsWith('```')) {
      jsonText = jsonText.substring(3).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    }

    try {
      console.log('‚úÖ Parsing JSON...');
      const evaluation = JSON.parse(jsonText) as { dimension_evaluations: DimensionEvaluation[] };
      console.log('‚úÖ JSON parsed successfully');

      // Validate structure
      if (!evaluation.dimension_evaluations || !Array.isArray(evaluation.dimension_evaluations)) {
        throw new Error('Invalid objective evaluation structure: missing dimension_evaluations array');
      }

      console.log('‚úÖ Objective evaluation valid');
      console.log('üìä Dimension evaluations count:', evaluation.dimension_evaluations.length);

      return evaluation;
    } catch (error: any) {
      console.error('‚ùå JSON PARSING ERROR in evaluateObjective:');
      console.error('Error message:', error.message);
      console.error('Cleaned JSON (first 1000 chars):', jsonText.substring(0, 1000));
      throw new Error(
        `Error al parsear respuesta JSON del AI para Objetivo ${objectiveNumber}: ${error.message}`
      );
    }
  }

  /**
   * Generate overall summary from all objective evaluations
   * This is called after all objectives have been evaluated individually
   */
  async generateOverallSummary(
    objectiveEvaluations: Record<number, { dimension_evaluations: DimensionEvaluation[] }>
  ): Promise<{
    overall_stage: number;
    overall_stage_label: 'Incipiente' | 'Emergente' | 'Avanzado' | 'Consolidado';
    strengths: string[];
    growth_areas: string[];
    summary: string;
    recommendations: string[];
  }> {
    console.log('üìä generateOverallSummary called');
    console.log('üìä Objective evaluations count:', Object.keys(objectiveEvaluations).length);

    // Collect all dimension evaluations
    const allDimensionEvaluations: DimensionEvaluation[] = [];
    for (const objNum of Object.keys(objectiveEvaluations).sort()) {
      const objEval = objectiveEvaluations[parseInt(objNum)];
      if (objEval?.dimension_evaluations) {
        allDimensionEvaluations.push(...objEval.dimension_evaluations);
      }
    }

    console.log('üìä Total dimension evaluations:', allDimensionEvaluations.length);

    // Build summary prompt
    const summaryPrompt = `Eres un experto en evaluaci√≥n educativa especializado en transformaci√≥n escolar en Chile.

Has evaluado las respuestas de una comunidad educativa sobre su nivel de transformaci√≥n en la v√≠a de Personalizaci√≥n.

A continuaci√≥n se presentan las evaluaciones detalladas de cada dimensi√≥n que ya has realizado.

Tu tarea ahora es generar un resumen ejecutivo que incluya:
1. Nivel general de transformaci√≥n (1-4)
2. Fortalezas principales (3-5 puntos)
3. √Åreas de crecimiento (3-5 puntos)
4. Resumen ejecutivo (2-3 oraciones)
5. Recomendaciones prioritarias (3-5 puntos)

## EVALUACIONES POR DIMENSI√ìN

${allDimensionEvaluations.map((dimEval, idx) => `
**Dimensi√≥n ${idx + 1}: ${dimEval.dimension}**
- Nivel asignado: ${dimEval.level}
- Justificaci√≥n: ${dimEval.reasoning}
- Evidencia: "${dimEval.evidence_quote}"
`).join('\n')}

## CRITERIOS PARA NIVEL GENERAL

El nivel general debe reflejar el promedio ponderado de todas las dimensiones, considerando:
- **Nivel 1 - Incipiente**: Promedio 1.0-1.5 - Conciencia inicial, intentos aislados
- **Nivel 2 - Emergente**: Promedio 1.6-2.5 - Pr√°cticas comenzando, resultados iniciales
- **Nivel 3 - Avanzado**: Promedio 2.6-3.5 - Implementaci√≥n generalizada, pr√°cticas institucionalizadas
- **Nivel 4 - Consolidado**: Promedio 3.6-4.0 - Excelencia sostenida, innovaci√≥n continua

## FORMATO DE SALIDA

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo esta estructura exacta:

{
  "overall_stage": 2,
  "overall_stage_label": "Emergente",
  "strengths": [
    "Fortaleza identificada 1",
    "Fortaleza identificada 2",
    "Fortaleza identificada 3"
  ],
  "growth_areas": [
    "√Årea de crecimiento 1",
    "√Årea de crecimiento 2",
    "√Årea de crecimiento 3"
  ],
  "summary": "Resumen ejecutivo del estado general de transformaci√≥n en 2-3 oraciones completas y coherentes.",
  "recommendations": [
    "Recomendaci√≥n prioritaria 1",
    "Recomendaci√≥n prioritaria 2",
    "Recomendaci√≥n prioritaria 3"
  ]
}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional antes o despu√©s.`;

    // Call Claude API
    console.log('‚úÖ Calling Anthropic API for overall summary...');
    const MODEL = 'claude-sonnet-4-20250514';
    console.log('üìã Using model:', MODEL);
    console.log('üìã Max tokens: 2000');
    console.log('üìã Temperature: 0.3');

    let message;
    try {
      message = await this.anthropic.messages.create({
        model: MODEL,
        max_tokens: 2000,
        temperature: 0.3,
        messages: [
          {
            role: 'user',
            content: summaryPrompt,
          },
        ],
      });
      console.log('‚úÖ API call successful');
      console.log('üìä Response usage:', {
        inputTokens: message.usage?.input_tokens || 0,
        outputTokens: message.usage?.output_tokens || 0
      });
    } catch (apiError: any) {
      console.error('‚ùå ANTHROPIC API ERROR in generateOverallSummary:');
      console.error('Error message:', apiError.message);
      throw new Error(
        `Error en llamada a Anthropic API para resumen general: ${apiError.message || 'Unknown error'}`
      );
    }

    // Extract JSON from response
    console.log('‚úÖ Extracting JSON from response...');
    const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
    console.log('üìä Response text length:', responseText.length);

    // Strip markdown code blocks if present
    let jsonText = responseText.trim();
    if (jsonText.startsWith('```json')) {
      jsonText = jsonText.substring(7).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    } else if (jsonText.startsWith('```')) {
      jsonText = jsonText.substring(3).trim();
      const lastBacktickIndex = jsonText.lastIndexOf('```');
      if (lastBacktickIndex !== -1) {
        jsonText = jsonText.substring(0, lastBacktickIndex);
      }
      jsonText = jsonText.trim();
    }

    try {
      console.log('‚úÖ Parsing JSON...');
      const summary = JSON.parse(jsonText);
      console.log('‚úÖ JSON parsed successfully');

      // Validate structure
      if (!summary.overall_stage || !summary.overall_stage_label ||
          !Array.isArray(summary.strengths) || !Array.isArray(summary.growth_areas) ||
          !summary.summary || !Array.isArray(summary.recommendations)) {
        throw new Error('Invalid summary structure');
      }

      console.log('‚úÖ Overall summary valid');
      console.log('üìä Overall stage:', summary.overall_stage, '-', summary.overall_stage_label);

      return summary;
    } catch (error: any) {
      console.error('‚ùå JSON PARSING ERROR in generateOverallSummary:');
      console.error('Error message:', error.message);
      console.error('Cleaned JSON (first 1000 chars):', jsonText.substring(0, 1000));
      throw new Error(
        `Error al parsear respuesta JSON del resumen general: ${error.message}`
      );
    }
  }

  /**
   * Build the evaluation context with responses and rubric
   */
  private buildEvaluationContext(
    responses: Record<string, DimensionResponse>,
    rubricItems: RubricItem[]
  ): string {
    let context = '## RESPUESTAS DE LA COMUNIDAD EDUCATIVA\n\n';

    // Group by objective and action
    const grouped = this.groupRubricItems(rubricItems);

    for (const objective of grouped) {
      context += `### Objetivo ${objective.objectiveNumber}: ${objective.objectiveText}\n\n`;

      for (const action of objective.actions) {
        context += `#### Acci√≥n ${action.actionNumber}: ${action.actionText}\n\n`;

        // Add each dimension response
        for (const [dimensionType, rubricItem] of Object.entries(action.dimensions)) {
          const item = rubricItem as RubricItem;  // Type assertion
          const response = responses[item.id];

          context += `**Dimensi√≥n: ${this.getDimensionLabel(dimensionType as any)}**\n`;
          context += `Rubric Item ID: ${item.id}\n\n`;

          context += `Descriptores de nivel:\n`;
          context += `- Nivel 1: ${item.level_1_descriptor}\n`;
          context += `- Nivel 2: ${item.level_2_descriptor}\n`;
          context += `- Nivel 3: ${item.level_3_descriptor}\n`;
          context += `- Nivel 4: ${item.level_4_descriptor}\n\n`;

          if (response && response.response && response.response.trim()) {
            context += `Respuesta del equipo:\n"${response.response}"\n\n`;
          } else {
            context += `Respuesta del equipo: (Sin respuesta)\n\n`;
          }

          context += '---\n\n';
        }
      }
    }

    return context;
  }

  /**
   * Group rubric items by objective and action
   */
  private groupRubricItems(rubricItems: RubricItem[]) {
    const objectivesMap: Record<number, any> = {};

    rubricItems.forEach((item) => {
      if (!objectivesMap[item.objective_number]) {
        objectivesMap[item.objective_number] = {
          objectiveNumber: item.objective_number,
          objectiveText: item.objective_text,
          actions: [],
        };
      }

      const objective = objectivesMap[item.objective_number];
      let action = objective.actions.find((a: any) => a.actionNumber === item.action_number);

      if (!action) {
        action = {
          actionNumber: item.action_number,
          actionText: item.action_text,
          dimensions: {},
        };
        objective.actions.push(action);
      }

      action.dimensions[item.dimension] = item;
    });

    const objectives = Object.values(objectivesMap).sort((a: any, b: any) => a.objectiveNumber - b.objectiveNumber);
    objectives.forEach((obj: any) => {
      obj.actions.sort((a: any, b: any) => a.actionNumber - b.actionNumber);
    });

    return objectives;
  }

  /**
   * Get Spanish label for dimension type
   */
  private getDimensionLabel(dimension: 'cobertura' | 'frecuencia' | 'profundidad'): string {
    const labels = {
      cobertura: 'Cobertura',
      frecuencia: 'Frecuencia',
      profundidad: 'Profundidad',
    };
    return labels[dimension];
  }

  /**
   * Validate evaluation structure
   */
  private isValidEvaluation(evaluation: any): evaluation is AssessmentEvaluation {
    return (
      evaluation &&
      typeof evaluation === 'object' &&
      Array.isArray(evaluation.dimension_evaluations) &&
      typeof evaluation.overall_stage === 'number' &&
      typeof evaluation.overall_stage_label === 'string' &&
      Array.isArray(evaluation.strengths) &&
      Array.isArray(evaluation.growth_areas) &&
      typeof evaluation.summary === 'string' &&
      Array.isArray(evaluation.recommendations)
    );
  }
}
